{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "487f962b",
   "metadata": {},
   "source": [
    "# Designing Selective Kinase Inhibitors\n",
    "## Initial Thoughts\n",
    "In accordance with the project specifications, I will be attempting to predict pKi of a compound given the SMILES representation of a molecule. After reviewing the data, I want to take two different approaches to the modeling and compare them to each other. The first approach will be based on the molecular descriptors available in RDKit, and will utilize a classic multilayer perceptron network. The second approach is a graph based convolutional neural network, utilizing the spatial relations contained in the SMILES molecular representation.\n",
    "\n",
    "## Molecular Descriptor-Based MLP\n",
    "The descriptor-based MLP process can be found in the following files, in the following order:\n",
    "1. MLPDataExploration.ipynb\n",
    "2. MLPDataProcessing.ipynb\n",
    "3. MLPModelDevelopment.ipynb\n",
    "\n",
    "## Atomic Structure GCN\n",
    "The atomic-structure graph based convolutional network can be found in the following files:\n",
    "1. GCNDataProcessing.ipynb\n",
    "2. GCNModelDevelopment.ipynb\n",
    "\n",
    "## Model Comparison\n",
    "The models are a bit difficult to compare on\n",
    "\n",
    "## Model Deployment\n",
    "As of the time of writing this, the molecular descriptor-based MLP is the best performing model, so I will write about the deployment of this model.\n",
    "\n",
    "The deployment of this model is actually going to be the deployment of 4 separate models: one for each of the kinases. Each model will output the pKi for it's respective kinase. The worst case scenario for the deployment of these models actually isn't the deployment failing, it's the deployment succeeding when it shouldn't. It's worse to serve incorrect information and predictions in this case than no information at all. To ensure that this doesn't happen, we will split all available data for each pKi into a training and a validation set. Whenever any of the models are updated, we will train them and ensure that the predictive performance is better than a certain baseline - as of now, I would set hard MSE requirements for each model individually.\n",
    "\n",
    "The model serving itself would come in 2 different part.\n",
    "1. Containerization of the Model \\\n",
    "Keras actually makes it quite easy to containerize models. I would host this model in some kind of environment with a GPU-accelerated embedded system to utilize CUDA and speed up the training and evaluation processes. Then, I would setup a REST API on the server including a query that passes in SMILES representations of molecules, or files containing these representations, and serves {SMILES, pKi} pairs back.\n",
    "\n",
    "2. Application Query of Model Container \\\n",
    "This could be any kind of general frontend. Personally, I would use Flask just to get a barebones application up and running quickly. \n",
    "* User Access:\n",
    "I'd include some kind of text box for raw input of SMILES strings, as well as a CSV upload to pass in representations of file strings which would prompt you to download a CSV file with the predictions back once the model server returned the answers.\n",
    "\n",
    "* Admin Access:\n",
    "Admin access would allow you to upload different training data as well, likely through a CSV format or this could be further customized. On training data upload, the training validation split that I talked about above would happen and if the validation benchmark passed, it would be accepted. If it failed, an error would be returned.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
